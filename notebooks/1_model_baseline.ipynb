{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7062fb8e-5c12-48b8-91c0-06de7c8f9967",
   "metadata": {},
   "source": [
    "# Polynomial and Decision Tree Regression on the Pantheon+ dataset\n",
    "\n",
    "This notebook will showcase using regression models from the scikit-learn module to predict apparent magnitudes using more features than what is done in the visualization notebook. We begin by importing the necessary modules and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a15bed5-ca0b-4b3a-bc73-c954831e3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocessing import preprocessor_simple, preprocess_des_data\n",
    "\n",
    "pantheonpluspath = '../data/Pantheon+SH0ES.dat'\n",
    "\n",
    "X1,y1 = preprocessor_simple(pantheonpluspath)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X1,y1,test_size = 0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb28cf6-8e8d-48db-aac1-794f3c1a8192",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "\n",
    "We can start with the Polynomial regressor. We can set up a simple 3rd degree polynomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b432ca5-4612-4911-b06a-72f3cb6831a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for polynomial fit with a 3 degree polynomial : 0.6831737322330402\n"
     ]
    }
   ],
   "source": [
    "poly1 = PolynomialFeatures(degree = 3, include_bias = False)\n",
    "\n",
    "poly_features = poly1.fit_transform(X_train)\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "\n",
    "poly_model.fit(poly_features,y_train)\n",
    "\n",
    "ypred = poly_model.predict(poly1.transform(X_valid))\n",
    "mae3d = mean_absolute_error(y_valid, ypred)\n",
    "\n",
    "\n",
    "print(f'MAE for polynomial fit with a 3 degree polynomial : {mae3d}')\n",
    "# print(ypred)\n",
    "# print(y1)\n",
    "# y1.head()\n",
    "\n",
    "# plt.scatter(X_train['zHD'],y_train)\n",
    "# plt.plot(X_valid,ypred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d3fe0-d3bd-4868-803c-e020bb43fde2",
   "metadata": {},
   "source": [
    "We will start with a Decision Tree Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9c12e9-e392-459e-a98e-c3ed5d33e54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for a Decision Tree Regressor : 0.1592869863013698\n"
     ]
    }
   ],
   "source": [
    "\n",
    "decTree = DecisionTreeRegressor(random_state = 0)\n",
    "decTree.fit(X_train,y_train)\n",
    "\n",
    "y_pred_decTree = decTree.predict(X_valid)\n",
    "\n",
    "mae_decTree = mean_absolute_error(y_valid,y_pred_decTree)\n",
    "print(f'MAE for a Decision Tree Regressor : {mae_decTree}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745d801-2e3f-4624-8e33-f286ca137b05",
   "metadata": {},
   "source": [
    "Right now, the Decision Tree looks like a better choice to predict the absolute magnitude of Type Ia supernovae from the redshift, stretch color and... We will fit some higher order polynomials to check if the MAE of the polynomial regressor improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9f9310-2d0d-41bb-a62e-89479ddf07df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4  5  6  7  8  9 10 11 12]\n",
      "MAE for a polynomial fit of degree 2 : 0.9910553371918874\n",
      "MAE for a polynomial fit of degree 3 : 0.6831737322330402\n",
      "MAE for a polynomial fit of degree 4 : 0.5399037633752826\n",
      "MAE for a polynomial fit of degree 5 : 0.44967846444245024\n",
      "MAE for a polynomial fit of degree 6 : 0.4979908839239662\n",
      "MAE for a polynomial fit of degree 7 : 0.9719012796887476\n",
      "MAE for a polynomial fit of degree 8 : 2.810116353956823\n",
      "MAE for a polynomial fit of degree 9 : 12.319525100429475\n",
      "MAE for a polynomial fit of degree 10 : 82.76626679452838\n",
      "MAE for a polynomial fit of degree 11 : 127.8432283311131\n",
      "MAE for a polynomial fit of degree 12 : 1126.1995839173442\n"
     ]
    }
   ],
   "source": [
    "def polynomial_fitter(X,y,degree):\n",
    "    poly1 = PolynomialFeatures(degree = degree,include_bias = False)\n",
    "    poly_features = poly1.fit_transform(X)\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(poly_features,y)\n",
    "    return poly_model,poly1\n",
    "    \n",
    "def maeforpoly(X_train,y_train,X_valid,y_valid,degree):\n",
    "    # poly1 = PolynomialFeatures(degree = degree,include_bias = False)\n",
    "    poly_model,poly1 = polynomial_fitter(X_train,y_train,degree)\n",
    "    ypreds = poly_model.predict(poly1.fit_transform(X_valid))\n",
    "    return mean_absolute_error(y_valid,ypreds)\n",
    "degreevals = np.linspace(2,12,11, dtype = 'int64')\n",
    "print(degreevals)\n",
    "for i in degreevals:\n",
    "    print(f'MAE for a polynomial fit of degree {i} : {maeforpoly(X_train,y_train,X_valid,y_valid,i)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219513cb-ce43-4841-ae78-faf0eacc046a",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "We can see that the the fit is best when we choose a polynomial of degree 5 as it gives the least MAE. But this is from the same Pantheon+ dataset. To validate these models in a more robust manner, we need to test it against a different dataset. For this, I will be using the Dark Energy Survey 5 Year Data release supernova dataset, which contains data of 1829 supernovae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2330ddc-c647-4faf-b656-5ea9d869b7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Decision Tree with test data : 0.31508775287042107\n"
     ]
    }
   ],
   "source": [
    "despath = '../data/DES-data.csv'\n",
    "X_test,y_test = preprocess_des_data(despath)\n",
    "decTree2 = DecisionTreeRegressor(random_state = 0)\n",
    "decTree2.fit(X1,y1)\n",
    "\n",
    "y_pred_decTree2 = decTree2.predict(X_test)\n",
    "maetest_decTree2 = mean_absolute_error(y_test,y_pred_decTree2)\n",
    "\n",
    "print(f'MAE for Decision Tree with test data : {maetest_decTree2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4909e770-93d4-401e-a289-1554a033b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for polynomial fit of degree 2 with test data : 1.1027774237234178\n",
      "MAE for polynomial fit of degree 3 with test data : 0.6544773386293322\n",
      "MAE for polynomial fit of degree 4 with test data : 0.5439427325541124\n",
      "MAE for polynomial fit of degree 5 with test data : 0.5823493367162379\n",
      "MAE for polynomial fit of degree 6 with test data : 0.6209551936299756\n",
      "MAE for polynomial fit of degree 7 with test data : 1.1527571774266439\n",
      "MAE for polynomial fit of degree 8 with test data : 2.088794860466574\n",
      "MAE for polynomial fit of degree 9 with test data : 9.391918942698457\n",
      "MAE for polynomial fit of degree 10 with test data : 13.131569200138129\n",
      "MAE for polynomial fit of degree 11 with test data : 43.309428062609726\n",
      "MAE for polynomial fit of degree 12 with test data : 190.8151573110611\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in degreevals:\n",
    "    print(f'MAE for polynomial fit of degree {i} with test data : {maeforpoly(X1,y1,X_test,y_test,i)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c545fa-463e-492b-a16a-bfe551f67792",
   "metadata": {},
   "source": [
    "We can conclude that the Decision Tree Regressor proves to be a better model to predict absolute magnitudes of supernovae from these three features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
